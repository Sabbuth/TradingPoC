{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f762b9f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Local use: load Santiment API key from a local env file\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "env_path = Path(\"santiment.env\")\n",
        "if env_path.exists():\n",
        "    for line in env_path.read_text().splitlines():\n",
        "        line = line.strip()\n",
        "        if not line or line.startswith(\"#\") or \"=\" not in line:\n",
        "            continue\n",
        "        key, _, value = line.partition(\"=\")\n",
        "        os.environ[key.strip()] = value.strip()\n",
        "\n",
        "API_KEY = os.environ.get(\"SANTIMENT_API_KEY\")\n",
        "\n",
        "print(API_KEY)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7707c30e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colab use: retrieve Santiment API key from Colab userdata\n",
        "from google.colab import userdata\n",
        "\n",
        "API_KEY = userdata.get(\"SANTIMENT_API_KEY\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6VKDppCji8U8",
      "metadata": {
        "id": "6VKDppCji8U8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Santiment API Client\n",
        "Retrieve social volume, weighted sentiment, exchange flows, addresses, MVRV, and NPL data\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Optional, Union\n",
        "import logging\n",
        "import pytz\n",
        "from pydantic import BaseModel\n",
        "\n",
        "try:\n",
        "    API_KEY  # type: ignore  # set by local or Colab cell\n",
        "except NameError:\n",
        "    API_KEY = os.environ.get('SANTIMENT_API_KEY')\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class SantimentData(BaseModel):\n",
        "    \"\"\"Data model for Santiment metrics\"\"\"\n",
        "    slug: str\n",
        "    metric: str\n",
        "    datetime: datetime\n",
        "    value: Union[float, int, None]\n",
        "    metadata: Optional[Dict] = {}\n",
        "\n",
        "class SantimentClient:\n",
        "    \"\"\"Client for Santiment API\"\"\"\n",
        "    \n",
        "    def __init__(self, api_key: str):\n",
        "        \"\"\"\n",
        "        Initialize Santiment client\n",
        "        \n",
        "        Args:\n",
        "            api_key: Santiment API key\n",
        "        \"\"\"\n",
        "        self.api_key = api_key\n",
        "        self.base_url = \"https://api.santiment.net/graphql\"\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'Authorization': f'Apikey {api_key}',\n",
        "            'Content-Type': 'application/json'\n",
        "        })\n",
        "        \n",
        "        # Rate limit tracking\n",
        "        self.rate_limit_info = {\n",
        "            'limit': None,                    # General limit\n",
        "            'remaining': None,                # General remaining\n",
        "            'limit_minute': None,\n",
        "            'remaining_minute': None,\n",
        "            'limit_hour': None,\n",
        "            'remaining_hour': None,\n",
        "            'limit_month': None,\n",
        "            'remaining_month': None,\n",
        "            'reset': None,\n",
        "            'last_updated': None\n",
        "        }\n",
        "        \n",
        "        # Available metrics\n",
        "        self.metrics = {\n",
        "            'social_volume': 'social_volume_total',\n",
        "            'weighted_sentiment': 'sentiment_balance_total',\n",
        "            'exchange_inflow': 'exchange_inflow',\n",
        "            'exchange_outflow': 'exchange_outflow',\n",
        "            'active_addresses': 'active_addresses_24h',\n",
        "            'mvrv_usd': 'mvrv_usd_30d',\n",
        "            'npl': 'network_profit_loss',\n",
        "            'marketcap_usd': 'marketcap_usd',\n",
        "            'price_usd': 'price_usd'\n",
        "        }\n",
        "    \n",
        "    def query_graphql(self, query: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Execute GraphQL query and extract rate limit information\n",
        "        \n",
        "        Returns:\n",
        "            Dict containing the GraphQL response data\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.session.post(\n",
        "                self.base_url,\n",
        "                json={'query': query},\n",
        "                timeout=30\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            \n",
        "            # Store response for header inspection\n",
        "            self.last_response = response\n",
        "            \n",
        "            # Extract rate limit headers\n",
        "            self._update_rate_limit_info(response.headers)\n",
        "            \n",
        "            return response.json()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            logger.error(f\"GraphQL query failed: {e}\")\n",
        "            raise\n",
        "    \n",
        "    def _update_rate_limit_info(self, headers: Dict):\n",
        "        \"\"\"Update rate limit information from response headers\"\"\"\n",
        "        # Parse exactly the same way - use direct key access like limit_minute\n",
        "        self.rate_limit_info['limit'] = headers.get('x-ratelimit-limit')\n",
        "        self.rate_limit_info['remaining'] = headers.get('x-ratelimit-remaining')\n",
        "        self.rate_limit_info['limit_minute'] = headers.get('x-ratelimit-limit-minute')\n",
        "        self.rate_limit_info['remaining_minute'] = headers.get('x-ratelimit-remaining-minute')\n",
        "        self.rate_limit_info['limit_hour'] = headers.get('x-ratelimit-limit-hour')\n",
        "        self.rate_limit_info['remaining_hour'] = headers.get('x-ratelimit-remaining-hour')\n",
        "        self.rate_limit_info['limit_month'] = headers.get('x-ratelimit-limit-month')\n",
        "        self.rate_limit_info['remaining_month'] = headers.get('x-ratelimit-remaining-month')\n",
        "        self.rate_limit_info['reset'] = headers.get('x-ratelimit-reset')\n",
        "        self.rate_limit_info['last_updated'] = datetime.now()\n",
        "        \n",
        "        # Log if rate limit is low\n",
        "        if self.rate_limit_info['remaining_minute']:\n",
        "            remaining = int(self.rate_limit_info['remaining_minute'])\n",
        "            if remaining < 3:\n",
        "                logger.warning(f\"Rate limit low: {remaining} calls remaining\")\n",
        "    \n",
        "    def get_rate_limit_status(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Get current rate limit status\n",
        "        \n",
        "        Returns:\n",
        "            Dict with rate limit information including ALL fields from rate_limit_info\n",
        "        \"\"\"\n",
        "        # Return a copy with ALL rate limit fields - don't filter anything\n",
        "        info = dict(self.rate_limit_info)  # Make sure we get all fields\n",
        "        \n",
        "        # Calculate usage percentages if we have both limit and remaining (optional calculations)\n",
        "        if info.get('limit_minute') and info.get('remaining_minute'):\n",
        "            try:\n",
        "                limit = int(info['limit_minute'])\n",
        "                remaining = int(info['remaining_minute'])\n",
        "                used = limit - remaining\n",
        "                info['used_minute'] = used\n",
        "                info['usage_percent_minute'] = (used / limit * 100) if limit > 0 else 0\n",
        "            except (ValueError, TypeError):\n",
        "                pass\n",
        "        \n",
        "        if info.get('limit_month') and info.get('remaining_month'):\n",
        "            try:\n",
        "                limit_month = int(info['limit_month'])\n",
        "                remaining_month = int(info['remaining_month'])\n",
        "                used_month = limit_month - remaining_month\n",
        "                info['used_month'] = used_month\n",
        "                info['usage_percent_month'] = (used_month / limit_month * 100) if limit_month > 0 else 0\n",
        "            except (ValueError, TypeError):\n",
        "                pass\n",
        "        \n",
        "        if info.get('reset'):\n",
        "            try:\n",
        "                reset_seconds = int(info['reset'])\n",
        "                reset_time = datetime.now() + timedelta(seconds=reset_seconds)\n",
        "                info['reset_time'] = reset_time\n",
        "            except (ValueError, TypeError):\n",
        "                pass\n",
        "        \n",
        "        return info\n",
        "    \n",
        "    def can_make_request(self, min_remaining: int = 1) -> bool:\n",
        "        \"\"\"\n",
        "        Check if it's safe to make an API request\n",
        "        \n",
        "        Args:\n",
        "            min_remaining: Minimum number of calls that should remain (default: 1)\n",
        "        \n",
        "        Returns:\n",
        "            True if safe to make request, False otherwise\n",
        "        \"\"\"\n",
        "        status = self.get_rate_limit_status()\n",
        "        if status['remaining_minute']:\n",
        "            return int(status['remaining_minute']) >= min_remaining\n",
        "        return True  # If we don't have rate limit info, assume it's safe\n",
        "    \n",
        "    def wait_for_rate_limit(self, min_remaining: int = 5):\n",
        "        \"\"\"\n",
        "        Wait if rate limit is too low\n",
        "        \n",
        "        Args:\n",
        "            min_remaining: Minimum number of calls that should remain before proceeding\n",
        "        \"\"\"\n",
        "        status = self.get_rate_limit_status()\n",
        "        if status['remaining_minute'] and int(status['remaining_minute']) < min_remaining:\n",
        "            if status['reset']:\n",
        "                reset_seconds = int(status['reset'])\n",
        "                logger.info(f\"Rate limit low. Waiting {reset_seconds} seconds for reset...\")\n",
        "                time.sleep(reset_seconds + 1)  # Wait a bit extra to be safe\n",
        "            else:\n",
        "                logger.warning(\"Rate limit low but no reset time available. Waiting 60 seconds...\")\n",
        "                time.sleep(60)\n",
        "    \n",
        "    def get_metric_data(\n",
        "        self,\n",
        "        slug: str,\n",
        "        metric: str,\n",
        "        from_date: datetime,\n",
        "        to_date: datetime,\n",
        "        interval: str = '1d'\n",
        "    ) -> List[SantimentData]:\n",
        "        \"\"\"\n",
        "        Get metric data for a specific asset\n",
        "        \n",
        "        Args:\n",
        "            slug: Asset slug (e.g., 'bitcoin', 'ethereum')\n",
        "            metric: Metric name from self.metrics\n",
        "            from_date: Start date\n",
        "            to_date: End date\n",
        "            interval: Time interval ('1h', '1d', '7d')\n",
        "        \"\"\"\n",
        "        \n",
        "        # Convert metric name to Santiment metric\n",
        "        santiment_metric = self.metrics.get(metric, metric)\n",
        "        \n",
        "        # Format dates\n",
        "        from_str = from_date.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "        to_str = to_date.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "        \n",
        "        query = f\"\"\"\n",
        "        {{\n",
        "            getMetric(metric: \"{santiment_metric}\") {{\n",
        "                timeseriesData(\n",
        "                    slug: \"{slug}\"\n",
        "                    from: \"{from_str}\"\n",
        "                    to: \"{to_str}\"\n",
        "                    interval: \"{interval}\"\n",
        "                ) {{\n",
        "                    datetime\n",
        "                    value\n",
        "                }}\n",
        "            }}\n",
        "        }}\n",
        "        \"\"\"\n",
        "        \n",
        "        try:\n",
        "            result = self.query_graphql(query)\n",
        "            \n",
        "            if 'errors' in result:\n",
        "                logger.error(f\"GraphQL errors: {result['errors']}\")\n",
        "                return []\n",
        "            \n",
        "            data_points = result.get('data', {}).get('getMetric', {}).get('timeseriesData', [])\n",
        "            \n",
        "            santiment_data = []\n",
        "            for point in data_points:\n",
        "                if point['value'] is not None:\n",
        "                    santiment_data.append(SantimentData(\n",
        "                        slug=slug,\n",
        "                        metric=metric,\n",
        "                        datetime=datetime.fromisoformat(point['datetime'].replace('Z', '+00:00')),\n",
        "                        value=point['value'],\n",
        "                        metadata={'santiment_metric': santiment_metric, 'interval': interval}\n",
        "                    ))\n",
        "            \n",
        "            logger.info(f\"Retrieved {len(santiment_data)} data points for {slug} {metric}\")\n",
        "            return santiment_data\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error retrieving {metric} for {slug}: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def get_social_volume(\n",
        "        self,\n",
        "        slug: str,\n",
        "        from_date: datetime,\n",
        "        to_date: datetime,\n",
        "        interval: str = '1d'\n",
        "    ) -> List[SantimentData]:\n",
        "        \"\"\"Get social volume data\"\"\"\n",
        "        return self.get_metric_data(slug, 'social_volume', from_date, to_date, interval)\n",
        "    \n",
        "    def get_weighted_sentiment(\n",
        "        self,\n",
        "        slug: str,\n",
        "        from_date: datetime,\n",
        "        to_date: datetime,\n",
        "        interval: str = '1d'\n",
        "    ) -> List[SantimentData]:\n",
        "        \"\"\"Get weighted sentiment data\"\"\"\n",
        "        return self.get_metric_data(slug, 'weighted_sentiment', from_date, to_date, interval)\n",
        "    \n",
        "    def get_exchange_flows(\n",
        "        self,\n",
        "        slug: str,\n",
        "        from_date: datetime,\n",
        "        to_date: datetime,\n",
        "        interval: str = '1d'\n",
        "    ) -> Dict[str, List[SantimentData]]:\n",
        "        \"\"\"Get exchange inflow and outflow data\"\"\"\n",
        "        inflow = self.get_metric_data(slug, 'exchange_inflow', from_date, to_date, interval)\n",
        "        outflow = self.get_metric_data(slug, 'exchange_outflow', from_date, to_date, interval)\n",
        "        \n",
        "        return {\n",
        "            'inflow': inflow,\n",
        "            'outflow': outflow\n",
        "        }\n",
        "    \n",
        "    def get_address_metrics(\n",
        "        self,\n",
        "        slug: str,\n",
        "        from_date: datetime,\n",
        "        to_date: datetime,\n",
        "        interval: str = '1d'\n",
        "    ) -> Dict[str, List[SantimentData]]:\n",
        "        \"\"\"Get address usage metrics (active addresses)\"\"\"\n",
        "        active = self.get_metric_data(slug, 'active_addresses', from_date, to_date, interval)\n",
        "        \n",
        "        return {\n",
        "            'active_addresses': active\n",
        "        }\n",
        "    \n",
        "    def get_mvrv(\n",
        "        self,\n",
        "        slug: str,\n",
        "        from_date: datetime,\n",
        "        to_date: datetime,\n",
        "        interval: str = '1d'\n",
        "    ) -> List[SantimentData]:\n",
        "        \"\"\"Get MVRV (Market Value to Realized Value) data\"\"\"\n",
        "        return self.get_metric_data(slug, 'mvrv_usd', from_date, to_date, interval)\n",
        "    \n",
        "    def get_price(\n",
        "        self,\n",
        "        slug: str,\n",
        "        from_date: datetime,\n",
        "        to_date: datetime,\n",
        "        interval: str = '1d'\n",
        "    ) -> List[SantimentData]:\n",
        "        \"\"\"Get price in USD\"\"\"\n",
        "        return self.get_metric_data(slug, 'price_usd', from_date, to_date, interval)\n",
        "    \n",
        "    def get_npl(\n",
        "        self,\n",
        "        slug: str,\n",
        "        from_date: datetime,\n",
        "        to_date: datetime,\n",
        "        interval: str = '1d'\n",
        "    ) -> List[SantimentData]:\n",
        "        \"\"\"Get Network Profit/Loss data\"\"\"\n",
        "        return self.get_metric_data(slug, 'npl', from_date, to_date, interval)\n",
        "    \n",
        "    def get_all_metrics(\n",
        "        self,\n",
        "        slug: str,\n",
        "        from_date: datetime,\n",
        "        to_date: datetime,\n",
        "        interval: str = '1d'\n",
        "    ) -> Dict[str, List[SantimentData]]:\n",
        "        \"\"\"\n",
        "        Get all available metrics for an asset\n",
        "        \n",
        "        Returns:\n",
        "            Dictionary with metric names as keys and data lists as values\n",
        "        \"\"\"\n",
        "        logger.info(f\"Fetching all metrics for {slug} from {from_date} to {to_date}\")\n",
        "        \n",
        "        all_data = {}\n",
        "        \n",
        "        # Social metrics\n",
        "        all_data['social_volume'] = self.get_social_volume(slug, from_date, to_date, interval)\n",
        "        all_data['weighted_sentiment'] = self.get_weighted_sentiment(slug, from_date, to_date, interval)\n",
        "        \n",
        "        # Exchange flow metrics\n",
        "        exchange_flows = self.get_exchange_flows(slug, from_date, to_date, interval)\n",
        "        all_data['exchange_inflow'] = exchange_flows['inflow']\n",
        "        all_data['exchange_outflow'] = exchange_flows['outflow']\n",
        "        \n",
        "        # Address metrics\n",
        "        address_metrics = self.get_address_metrics(slug, from_date, to_date, interval)\n",
        "        all_data['active_addresses'] = address_metrics['active_addresses']\n",
        "        \n",
        "        # Financial metrics\n",
        "        all_data['mvrv_usd'] = self.get_mvrv(slug, from_date, to_date, interval)\n",
        "        all_data['npl'] = self.get_npl(slug, from_date, to_date, interval)\n",
        "        \n",
        "        # Summary\n",
        "        total_points = sum(len(data) for data in all_data.values())\n",
        "        logger.info(f\"Retrieved {total_points} total data points across {len(all_data)} metrics\")\n",
        "        \n",
        "        return all_data\n",
        "    \n",
        "    def to_dataframe(self, data: List[SantimentData]) -> pd.DataFrame:\n",
        "        \"\"\"Convert SantimentData list to pandas DataFrame\"\"\"\n",
        "        if not data:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        df_data = []\n",
        "        for item in data:\n",
        "            df_data.append({\n",
        "                'slug': item.slug,\n",
        "                'metric': item.metric,\n",
        "                'datetime': item.datetime,\n",
        "                'value': item.value,\n",
        "                'santiment_metric': item.metadata.get('santiment_metric'),\n",
        "                'interval': item.metadata.get('interval')\n",
        "            })\n",
        "        \n",
        "        df = pd.DataFrame(df_data)\n",
        "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
        "        df = df.set_index('datetime')\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def get_available_assets(self) -> List[str]:\n",
        "        \"\"\"Get list of available asset slugs\"\"\"\n",
        "        query = \"\"\"\n",
        "        {\n",
        "            allProjects {\n",
        "                slug\n",
        "                name\n",
        "                ticker\n",
        "            }\n",
        "        }\n",
        "        \"\"\"\n",
        "        \n",
        "        try:\n",
        "            result = self.query_graphql(query)\n",
        "            projects = result.get('data', {}).get('allProjects', [])\n",
        "            \n",
        "            asset_list = []\n",
        "            for project in projects:\n",
        "                asset_list.append({\n",
        "                    'slug': project['slug'],\n",
        "                    'name': project['name'],\n",
        "                    'ticker': project['ticker']\n",
        "                })\n",
        "            \n",
        "            logger.info(f\"Found {len(asset_list)} available assets\")\n",
        "            return asset_list\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error retrieving available assets: {e}\")\n",
        "            return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "Pk0m1TksQof9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pk0m1TksQof9",
        "outputId": "ff0a9008-7d19-48c6-a34c-06bacc4854a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¡ Fetching Bitcoin metrics...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\pavau\\AppData\\Local\\Temp\\ipykernel_32512\\305974814.py:5: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  to_date = datetime.utcnow() - timedelta(days=60)     # 2 months ago\n",
            "C:\\Users\\pavau\\AppData\\Local\\Temp\\ipykernel_32512\\305974814.py:6: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  from_date = datetime.utcnow() - timedelta(days=240)  # 8 months ago\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'SantimentClient' object has no attribute 'get_market_cap_usd'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ“¡ Fetching Bitcoin metrics...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Fetch price (via market_cap_usd)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m price_data = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_market_cap_usd\u001b[49m(slug, from_date, to_date, interval=\u001b[33m\"\u001b[39m\u001b[33m1d\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m price_df = client.to_dataframe(price_data)[[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m]].rename(columns={\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m     16\u001b[39m metric_dfs = {\u001b[33m\"\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m\"\u001b[39m: price_df}\n",
            "\u001b[31mAttributeError\u001b[39m: 'SantimentClient' object has no attribute 'get_market_cap_usd'"
          ]
        }
      ],
      "source": [
        "# Initialize client\n",
        "client = SantimentClient(API_KEY)\n",
        "\n",
        "# Time range\n",
        "to_date = datetime.utcnow() - timedelta(days=60)     # 2 months ago\n",
        "from_date = datetime.utcnow() - timedelta(days=240)  # 8 months ago\n",
        "\n",
        "slug = \"bitcoin\"\n",
        "\n",
        "print(\"ğŸ“¡ Fetching Bitcoin metrics...\")\n",
        "\n",
        "# Fetch price (via market_cap_usd)\n",
        "price_data = client.get_market_cap_usd(slug, from_date, to_date, interval=\"1d\")\n",
        "price_df = client.to_dataframe(price_data)[[\"value\"]].rename(columns={\"value\": \"price\"})\n",
        "\n",
        "metric_dfs = {\"price\": price_df}\n",
        "\n",
        "# Fetch all other metrics available in the client\n",
        "for metric in client.metrics.keys():\n",
        "    if metric == \"market_cap_usd\":\n",
        "        continue  # Already used as price\n",
        "\n",
        "    print(f\" â†’ Fetching {metric} ...\")\n",
        "    data = client.get_metric_data(slug, metric, from_date, to_date, interval=\"1d\")\n",
        "    df = client.to_dataframe(data)\n",
        "    print(f\"   Returned shape for metric {metric}: {df.shape}\")\n",
        "\n",
        "    if df.empty:\n",
        "        print(f\"   âš ï¸ No data returned for {metric}\")\n",
        "        continue\n",
        "\n",
        "    df = df[[\"value\"]].rename(columns={\"value\": metric})\n",
        "    metric_dfs[metric] = df\n",
        "\n",
        "# Merge all metrics on datetime\n",
        "print(\"\\nğŸ”„ Merging all time series...\")\n",
        "merged_df = pd.concat(metric_dfs.values(), axis=1, join=\"inner\")\n",
        "\n",
        "print(f\"ğŸ“Š Final dataset shape: {merged_df.shape}\")\n",
        "\n",
        "# -----------------------------\n",
        "# FULL CORRELATION MATRIX\n",
        "# -----------------------------\n",
        "full_corr_matrix = merged_df.corr()\n",
        "\n",
        "# -----------------------------\n",
        "# CORRELATION vs PRICE (sorted)\n",
        "# -----------------------------\n",
        "corr_vs_price = full_corr_matrix[[\"price\"]].sort_values(\"price\", ascending=False)\n",
        "\n",
        "print(\"\\n===== ğŸ“ˆ Correlation vs Bitcoin Price (sorted) =====\\n\")\n",
        "display(corr_vs_price)\n",
        "\n",
        "print(\"\\n===== ğŸ” Full Correlation Matrix (all variables vs each other) =====\\n\")\n",
        "display(full_corr_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1b5f3927",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§ª Single API Call Rate Limit Test\n",
            "================================================================================\n",
            "\n",
            "ğŸ“‹ Test Configuration:\n",
            "   Assets: Bitcoin, Ethereum, Cardano, Solana, Chainlink, Uniswap, Polygon, Avalanche, Polkadot, Litecoin, Bitcoin-Cash, Stellar, Algorand, Cosmos, Tezos, Filecoin, Aave, Compound, Maker, Dash, Monero, Zcash, Eos, Tron, Neo, Vechain, Theta, Fantom, Near, Aptos, Sui, Arbitrum, Optimism, Base, Celestia, Injective, Sei, Sei-Network, Render-Token, Fetch-Ai\n",
            "   Metrics: Active Addresses, Price Usd, Marketcap Usd, Exchange Inflow, Exchange Outflow, Social Volume, Weighted Sentiment, Npl\n",
            "   Total queries: 40 assets Ã— 8 metrics = 320 getMetric calls\n",
            "   Date range: 2025-09-14 to 2025-10-14\n",
            "\n",
            "ğŸ“Š Rate Limit Status BEFORE API Call:\n",
            "\n",
            "================================================================================\n",
            "ğŸ“‹ INSPECTING API RESPONSE HEADERS\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "ConnectionError",
          "evalue": "('Connection aborted.', PermissionError(13, 'Permission denied'))",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connection.py:790\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connection.py:922\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    921\u001b[39m     default_ssl_context = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m     context = \u001b[43mcreate_urllib3_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolve_ssl_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolve_cert_reqs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\util\\ssl_.py:369\u001b[39m, in \u001b[36mcreate_urllib3_context\u001b[39m\u001b[34m(ssl_version, cert_reqs, options, ciphers, ssl_minimum_version, ssl_maximum_version, verify_flags)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sslkeylogfile:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeylog_filename\u001b[49m = sslkeylogfile\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m context\n",
            "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '\\\\\\\\?\\\\Volume{ba5fbc33-b5dd-4468-b9fb-349269ef43b8}\\\\virtual_file.log'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mProtocolError\u001b[39m                             Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\util\\util.py:38\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value.__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connection.py:790\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connection.py:922\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    921\u001b[39m     default_ssl_context = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m922\u001b[39m     context = \u001b[43mcreate_urllib3_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolve_ssl_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolve_cert_reqs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\util\\ssl_.py:369\u001b[39m, in \u001b[36mcreate_urllib3_context\u001b[39m\u001b[34m(ssl_version, cert_reqs, options, ciphers, ssl_minimum_version, ssl_maximum_version, verify_flags)\u001b[39m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sslkeylogfile:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeylog_filename\u001b[49m = sslkeylogfile\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m context\n",
            "\u001b[31mProtocolError\u001b[39m: ('Connection aborted.', PermissionError(13, 'Permission denied'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m80\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m test_query = \u001b[33m'\u001b[39m\u001b[33m{\u001b[39m\u001b[33m getMetric(metric: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mactive_addresses_24h\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m) \u001b[39m\u001b[33m{\u001b[39m\u001b[33m timeseriesData(slug: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbitcoin\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, from: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m2025-01-01T00:00:00Z\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, to: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m2025-01-02T00:00:00Z\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, interval: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m1d\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m) \u001b[39m\u001b[33m{\u001b[39m\u001b[33m datetime value } } }\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m test_response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_query\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m test_response.raise_for_status()\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Update rate limit info from headers\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\requests\\sessions.py:637\u001b[39m, in \u001b[36mSession.post\u001b[39m\u001b[34m(self, url, data, json, **kwargs)\u001b[39m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    627\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    628\u001b[39m \n\u001b[32m    629\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    634\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    635\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\requests\\adapters.py:659\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    644\u001b[39m     resp = conn.urlopen(\n\u001b[32m    645\u001b[39m         method=request.method,\n\u001b[32m    646\u001b[39m         url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    655\u001b[39m         chunked=chunked,\n\u001b[32m    656\u001b[39m     )\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    662\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, ConnectTimeoutError):\n\u001b[32m    663\u001b[39m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
            "\u001b[31mConnectionError\u001b[39m: ('Connection aborted.', PermissionError(13, 'Permission denied'))"
          ]
        }
      ],
      "source": [
        "# ğŸ§ª TEST: Single API Call Rate Limit Analysis\n",
        "print(\"ğŸ§ª Single API Call Rate Limit Test\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "client = SantimentClient(API_KEY)\n",
        "\n",
        "# Test configuration\n",
        "test_assets = ['bitcoin', 'ethereum', 'cardano', 'solana', 'chainlink', 'uniswap', 'polygon', 'avalanche', 'polkadot', 'litecoin', 'bitcoin-cash', 'stellar', 'algorand', 'cosmos', 'tezos', 'filecoin', 'aave', 'compound', 'maker', 'dash']  # Twenty assets\n",
        "test_assets.extend(['monero', 'zcash', 'eos', 'tron', 'neo', 'vechain', 'theta', 'fantom', 'near', 'aptos'])  # Add 10 more assets\n",
        "test_assets.extend(['sui', 'arbitrum', 'optimism', 'base', 'celestia', 'injective', 'sei', 'sei-network', 'render-token', 'fetch-ai'])  # Add 10 more assets\n",
        "test_metrics = ['active_addresses', 'price_usd', 'marketcap_usd', 'exchange_inflow', 'exchange_outflow', 'social_volume', 'weighted_sentiment', 'npl']  # Nine metrics for each asset (all available)\n",
        "test_start = datetime.now() - timedelta(days=90)\n",
        "test_end = datetime.now() - timedelta(days=60)\n",
        "\n",
        "print(f\"\\nğŸ“‹ Test Configuration:\")\n",
        "print(f\"   Assets: {', '.join([asset.title() for asset in test_assets])}\")\n",
        "print(f\"   Metrics: {', '.join([metric.replace('_', ' ').title() for metric in test_metrics])}\")\n",
        "print(f\"   Total queries: {len(test_assets)} assets Ã— {len(test_metrics)} metrics = {len(test_assets) * len(test_metrics)} getMetric calls\")\n",
        "print(f\"   Date range: {test_start.date()} to {test_end.date()}\")\n",
        "\n",
        "# Get rate limit BEFORE making the call - ensure we have enough time before window reset\n",
        "print(f\"\\nğŸ“Š Rate Limit Status BEFORE API Call:\")\n",
        "\n",
        "# Make a test call to inspect ALL headers\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"ğŸ“‹ INSPECTING API RESPONSE HEADERS\")\n",
        "print(f\"{'='*80}\")\n",
        "test_query = '{ getMetric(metric: \"active_addresses_24h\") { timeseriesData(slug: \"bitcoin\", from: \"2025-01-01T00:00:00Z\", to: \"2025-01-02T00:00:00Z\", interval: \"1d\") { datetime value } } }'\n",
        "test_response = client.session.post(client.base_url, json={'query': test_query}, timeout=30)\n",
        "test_response.raise_for_status()\n",
        "# Update rate limit info from headers\n",
        "client._update_rate_limit_info(test_response.headers)\n",
        "\n",
        "# Remove header printing - we know they're there, just parse them\n",
        "\n",
        "# Make a test call to get headers BEFORE\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"ğŸ“Š HEADERS BEFORE API CALL\")\n",
        "print(f\"{'='*80}\")\n",
        "test_query = '{ getMetric(metric: \"active_addresses_24h\") { timeseriesData(slug: \"bitcoin\", from: \"2025-01-01T00:00:00Z\", to: \"2025-01-02T00:00:00Z\", interval: \"1d\") { datetime value } } }'\n",
        "response_before = client.session.post(client.base_url, json={'query': test_query}, timeout=30)\n",
        "response_before.raise_for_status()\n",
        "\n",
        "print(\"\\nResponse Headers BEFORE:\")\n",
        "for header, value in response_before.headers.items():\n",
        "    print(f\"   {header}: {value}\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"ğŸ”„ Making Single API Call...\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Make the API call - Single call for two assets and two metrics using GraphQL aliases\n",
        "try:\n",
        "    # Create GraphQL query with aliases to query both assets and both metrics in one call\n",
        "    from_str = test_start.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "    to_str = test_end.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
        "    \n",
        "    # Build query with aliases for each asset-metric combination\n",
        "    query_parts = []\n",
        "    for asset in test_assets:\n",
        "        for metric in test_metrics:\n",
        "            santiment_metric = client.metrics.get(metric, metric)\n",
        "            alias = f\"{asset.replace('-', '_')}_{metric.replace('-', '_')}\"\n",
        "            query_parts.append(f\"\"\"\n",
        "            {alias}: getMetric(metric: \"{santiment_metric}\") {{\n",
        "                timeseriesData(\n",
        "                    slug: \"{asset}\"\n",
        "                    from: \"{from_str}\"\n",
        "                    to: \"{to_str}\"\n",
        "                    interval: \"5m\"\n",
        "                ) {{\n",
        "                    datetime\n",
        "                    value\n",
        "                }}\n",
        "            }}\n",
        "        \"\"\")\n",
        "    \n",
        "    query = \"{\" + \"\".join(query_parts) + \"}\"\n",
        "    \n",
        "    # Execute the API call and capture response\n",
        "    result = client.query_graphql(query)\n",
        "    \n",
        "    # Get headers AFTER the call\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"ğŸ“Š HEADERS AFTER API CALL\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    # Access the last response from the client\n",
        "    if hasattr(client, 'last_response') and client.last_response:\n",
        "        response_after = client.last_response\n",
        "        print(\"\\nResponse Headers AFTER:\")\n",
        "        for header, value in response_after.headers.items():\n",
        "            print(f\"   {header}: {value}\")\n",
        "    else:\n",
        "        # Make another call to get headers after\n",
        "        test_query_after = '{ getMetric(metric: \"active_addresses_24h\") { timeseriesData(slug: \"bitcoin\", from: \"2025-01-01T00:00:00Z\", to: \"2025-01-02T00:00:00Z\", interval: \"1d\") { datetime value } } }'\n",
        "        response_after = client.session.post(client.base_url, json={'query': test_query_after}, timeout=30)\n",
        "        response_after.raise_for_status()\n",
        "        print(\"\\nResponse Headers AFTER:\")\n",
        "        for header, value in response_after.headers.items():\n",
        "            print(f\"   {header}: {value}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"   âŒ Error making API call: {str(e)[:100]}...\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(f\"\\nâœ… Single API call test complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8bba08ab",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:GraphQL query failed: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âŒ Error fetching tickers and slugs: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
            "    response = self._make_request(\n",
            "        conn,\n",
            "    ...<10 lines>...\n",
            "        **response_kw,\n",
            "    )\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n",
            "    raise new_e\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n",
            "    self._validate_conn(conn)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n",
            "    conn.connect()\n",
            "    ~~~~~~~~~~~~^^\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connection.py\", line 790, in connect\n",
            "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
            "        sock=sock,\n",
            "    ...<14 lines>...\n",
            "        assert_fingerprint=self.assert_fingerprint,\n",
            "    )\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connection.py\", line 922, in _ssl_wrap_socket_and_match_hostname\n",
            "    context = create_urllib3_context(\n",
            "        ssl_version=resolve_ssl_version(ssl_version),\n",
            "    ...<2 lines>...\n",
            "        cert_reqs=resolve_cert_reqs(cert_reqs),\n",
            "    )\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\util\\ssl_.py\", line 369, in create_urllib3_context\n",
            "    context.keylog_filename = sslkeylogfile\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "PermissionError: [Errno 13] Permission denied: '\\\\\\\\?\\\\Volume{ba5fbc33-b5dd-4468-b9fb-349269ef43b8}\\\\virtual_file.log'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\requests\\adapters.py\", line 644, in send\n",
            "    resp = conn.urlopen(\n",
            "        method=request.method,\n",
            "    ...<9 lines>...\n",
            "        chunked=chunked,\n",
            "    )\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n",
            "    retries = retries.increment(\n",
            "        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n",
            "    )\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 474, in increment\n",
            "    raise reraise(type(error), error, _stacktrace)\n",
            "          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\util\\util.py\", line 38, in reraise\n",
            "    raise value.with_traceback(tb)\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n",
            "    response = self._make_request(\n",
            "        conn,\n",
            "    ...<10 lines>...\n",
            "        **response_kw,\n",
            "    )\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n",
            "    raise new_e\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n",
            "    self._validate_conn(conn)\n",
            "    ~~~~~~~~~~~~~~~~~~~^^^^^^\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n",
            "    conn.connect()\n",
            "    ~~~~~~~~~~~~^^\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connection.py\", line 790, in connect\n",
            "    sock_and_verified = _ssl_wrap_socket_and_match_hostname(\n",
            "        sock=sock,\n",
            "    ...<14 lines>...\n",
            "        assert_fingerprint=self.assert_fingerprint,\n",
            "    )\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\connection.py\", line 922, in _ssl_wrap_socket_and_match_hostname\n",
            "    context = create_urllib3_context(\n",
            "        ssl_version=resolve_ssl_version(ssl_version),\n",
            "    ...<2 lines>...\n",
            "        cert_reqs=resolve_cert_reqs(cert_reqs),\n",
            "    )\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\urllib3\\util\\ssl_.py\", line 369, in create_urllib3_context\n",
            "    context.keylog_filename = sslkeylogfile\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "urllib3.exceptions.ProtocolError: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\pavau\\AppData\\Local\\Temp\\ipykernel_32512\\2202703054.py\", line 21, in <module>\n",
            "    result = client.query_graphql(tickers_slugs_query)\n",
            "  File \"C:\\Users\\pavau\\AppData\\Local\\Temp\\ipykernel_32512\\1041795031.py\", line 85, in query_graphql\n",
            "    response = self.session.post(\n",
            "        self.base_url,\n",
            "        json={'query': query},\n",
            "        timeout=30\n",
            "    )\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\requests\\sessions.py\", line 637, in post\n",
            "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
            "           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"c:\\Users\\pavau\\anaconda3\\envs\\Proofofconcept\\Lib\\site-packages\\requests\\adapters.py\", line 659, in send\n",
            "    raise ConnectionError(err, request=request)\n",
            "requests.exceptions.ConnectionError: ('Connection aborted.', PermissionError(13, 'Permission denied'))\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Get list of all tickers and slugs from Santiment API\n",
        "\"\"\"\n",
        "\n",
        "client = SantimentClient(API_KEY)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Query for all assets with tickers, slugs, and market segment\n",
        "tickers_slugs_query = \"\"\"\n",
        "{\n",
        "  allProjects {\n",
        "    ticker\n",
        "    slug\n",
        "    marketSegment\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    result = client.query_graphql(tickers_slugs_query)\n",
        "    projects = result.get('data', {}).get('allProjects', [])\n",
        "    \n",
        "    # Create DataFrame with ticker, slug, and market segment\n",
        "    df = pd.DataFrame(projects)\n",
        "    \n",
        "    # Sort by ticker for easier reading\n",
        "    df = df.sort_values('ticker').reset_index(drop=True)\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"ğŸ“‹ Tickers, Slugs, and Market Segments\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nâœ… Found {len(df)} assets\\n\")\n",
        "    print(df.to_string(index=False))\n",
        "    \n",
        "    # Also create a simple mapping dictionary\n",
        "    ticker_to_slug = {row['ticker']: row['slug'] for _, row in df.iterrows() if row['ticker']}\n",
        "    slug_to_ticker = {row['slug']: row['ticker'] for _, row in df.iterrows() if row['slug']}\n",
        "    \n",
        "    print(f\"\\nğŸ’¡ Variables created:\")\n",
        "    print(f\"   - df: DataFrame with ticker, slug, and marketSegment columns\")\n",
        "    print(f\"   - ticker_to_slug: Dictionary mapping ticker â†’ slug\")\n",
        "    print(f\"   - slug_to_ticker: Dictionary mapping slug â†’ ticker\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error fetching tickers and slugs: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ada59b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ğŸ” Duplicate Tickers Analysis\n",
            "================================================================================\n",
            "\n",
            "âœ… Found 282 tickers with duplicates (631 total assets)\n",
            "\n",
            "Duplicate tickers:\n",
            "   FRAX: 7 assets\n",
            "   USDT: 7 assets\n",
            "   USDC: 7 assets\n",
            "   DAI: 6 assets\n",
            "   MIM: 5 assets\n",
            "   BUSD: 4 assets\n",
            "   TRUMP: 4 assets\n",
            "   SHIDO: 4 assets\n",
            "   BLOCK: 4 assets\n",
            "   WBTC: 4 assets\n",
            "   WETH: 4 assets\n",
            "   BROCCOLI: 4 assets\n",
            "   MAGA: 3 assets\n",
            "   RAIN: 3 assets\n",
            "   BAL: 3 assets\n",
            "   SPX: 3 assets\n",
            "   NEIRO: 3 assets\n",
            "   NCT: 3 assets\n",
            "   BIFI: 3 assets\n",
            "   CAT: 3 assets\n",
            "\n",
            "================================================================================\n",
            "ğŸ“‹ Example: Assets with ticker 'DOGE'\n",
            "================================================================================\n",
            "                                     slug                                              name ticker     id infrastructure  marketSegment\n",
            "                                 dogecoin                                          Dogecoin   DOGE 234314       Dogecoin Cryptocurrency\n",
            "department-of-government-efficiency-token Department Of Government Efficiency (dogegov.com)   DOGE 238996            ETH       Ethereum\n",
            "\n",
            "================================================================================\n",
            "ğŸ“Š Field Availability for Duplicate Tickers\n",
            "================================================================================\n",
            "\n",
            "Non-null field counts:\n",
            "   name: 631/631 (100.0%)\n",
            "   id: 631/631 (100.0%)\n",
            "   infrastructure: 417/631 (66.1%)\n",
            "   marketSegment: 409/631 (64.8%)\n",
            "\n",
            "ğŸ’¡ Key points:\n",
            "   - Use 'slug' as the unique identifier (required for API queries)\n",
            "   - 'name' field can help distinguish assets with same ticker\n",
            "   - 'infrastructure' field shows the blockchain (if available)\n",
            "   - 'mainContractAddress' shows the contract address (if available)\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Check for duplicate tickers and see what fields are available to distinguish them\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Query for all assets with additional fields that might help distinguish them\n",
        "detailed_query = \"\"\"\n",
        "{\n",
        "  allProjects {\n",
        "    slug\n",
        "    name\n",
        "    ticker\n",
        "    id\n",
        "    infrastructure\n",
        "    marketSegment\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    result = client.query_graphql(detailed_query)\n",
        "    projects = result.get('data', {}).get('allProjects', [])\n",
        "    \n",
        "    df = pd.DataFrame(projects)\n",
        "    \n",
        "    # Find duplicate tickers\n",
        "    ticker_counts = Counter(df['ticker'].dropna())\n",
        "    duplicates = {ticker: count for ticker, count in ticker_counts.items() if count > 1}\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"ğŸ” Duplicate Tickers Analysis\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nâœ… Found {len(duplicates)} tickers with duplicates ({sum(duplicates.values())} total assets)\\n\")\n",
        "    \n",
        "    if duplicates:\n",
        "        print(\"Duplicate tickers:\")\n",
        "        for ticker, count in sorted(duplicates.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
        "            print(f\"   {ticker}: {count} assets\")\n",
        "        \n",
        "        # Show examples of duplicate tickers\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ“‹ Example: Assets with ticker 'DOGE'\")\n",
        "        print(\"=\" * 80)\n",
        "        doge_assets = df[df['ticker'] == 'DOGE'][['slug', 'name', 'ticker', 'id', 'infrastructure', 'marketSegment']]\n",
        "        print(doge_assets.to_string(index=False))\n",
        "        \n",
        "        # Show what fields are available and non-null\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"ğŸ“Š Field Availability for Duplicate Tickers\")\n",
        "        print(\"=\" * 80)\n",
        "        duplicate_df = df[df['ticker'].isin(duplicates.keys())]\n",
        "        print(\"\\nNon-null field counts:\")\n",
        "        for col in ['name', 'id', 'infrastructure', 'marketSegment']:\n",
        "            non_null = duplicate_df[col].notna().sum()\n",
        "            print(f\"   {col}: {non_null}/{len(duplicate_df)} ({100*non_null/len(duplicate_df):.1f}%)\")\n",
        "    \n",
        "    # Save the detailed dataframe\n",
        "    detailed_assets_df = df\n",
        "    \n",
        "    print(\"\\nğŸ’¡ Key points:\")\n",
        "    print(\"   - Use 'slug' as the unique identifier (required for API queries)\")\n",
        "    print(\"   - 'name' field can help distinguish assets with same ticker\")\n",
        "    print(\"   - 'id' is a unique numeric identifier for each asset\")\n",
        "    print(\"   - 'infrastructure' field shows the blockchain/platform (e.g., 'ethereum', 'bitcoin')\")\n",
        "    print(\"   - 'marketSegment' provides additional categorization\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c85e1b3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Helper functions for working with duplicate tickers\n",
        "\"\"\"\n",
        "\n",
        "def get_slugs_by_ticker(ticker: str, df: pd.DataFrame = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Get all slugs for a given ticker\n",
        "    \n",
        "    Args:\n",
        "        ticker: Ticker symbol (e.g., 'DOGE', 'USDT')\n",
        "        df: DataFrame from detailed_assets_df (if None, uses the one from previous cell)\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with all assets matching the ticker\n",
        "    \"\"\"\n",
        "    if df is None:\n",
        "        try:\n",
        "            df = detailed_assets_df\n",
        "        except NameError:\n",
        "            print(\"âŒ detailed_assets_df not found. Run the duplicate tickers analysis cell first.\")\n",
        "            return pd.DataFrame()\n",
        "    \n",
        "    matches = df[df['ticker'] == ticker.upper()].copy()\n",
        "    return matches[['slug', 'name', 'ticker', 'id', 'infrastructure', 'marketSegment']]\n",
        "\n",
        "\n",
        "def get_slug_by_ticker_and_infrastructure(ticker: str, infrastructure: str = None, df: pd.DataFrame = None) -> str:\n",
        "    \"\"\"\n",
        "    Get slug for a ticker, optionally filtered by infrastructure\n",
        "    \n",
        "    Args:\n",
        "        ticker: Ticker symbol\n",
        "        infrastructure: Optional infrastructure filter (e.g., 'ETH', 'Dogecoin')\n",
        "        df: DataFrame from detailed_assets_df\n",
        "    \n",
        "    Returns:\n",
        "        Slug string, or None if not found/ambiguous\n",
        "    \"\"\"\n",
        "    matches = get_slugs_by_ticker(ticker, df)\n",
        "    \n",
        "    if len(matches) == 0:\n",
        "        print(f\"âŒ No assets found with ticker '{ticker}'\")\n",
        "        return None\n",
        "    \n",
        "    if infrastructure:\n",
        "        matches = matches[matches['infrastructure'].str.contains(infrastructure, case=False, na=False)]\n",
        "        if len(matches) == 0:\n",
        "            print(f\"âŒ No assets found with ticker '{ticker}' and infrastructure '{infrastructure}'\")\n",
        "            return None\n",
        "    \n",
        "    if len(matches) == 1:\n",
        "        return matches.iloc[0]['slug']\n",
        "    else:\n",
        "        print(f\"âš ï¸  Multiple matches found for '{ticker}':\")\n",
        "        print(matches[['slug', 'name', 'infrastructure']].to_string(index=False))\n",
        "        print(f\"\\nğŸ’¡ Use get_slugs_by_ticker('{ticker}') to see all options\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def filter_duplicates_by_infrastructure(df: pd.DataFrame = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Show duplicate tickers grouped by infrastructure\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame from detailed_assets_df\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame showing duplicates grouped by ticker and infrastructure\n",
        "    \"\"\"\n",
        "    if df is None:\n",
        "        try:\n",
        "            df = detailed_assets_df\n",
        "        except NameError:\n",
        "            print(\"âŒ detailed_assets_df not found. Run the duplicate tickers analysis cell first.\")\n",
        "            return pd.DataFrame()\n",
        "    \n",
        "    # Get duplicates\n",
        "    ticker_counts = df['ticker'].value_counts()\n",
        "    duplicate_tickers = ticker_counts[ticker_counts > 1].index\n",
        "    \n",
        "    # Filter and group\n",
        "    duplicates_df = df[df['ticker'].isin(duplicate_tickers)].copy()\n",
        "    duplicates_df = duplicates_df.sort_values(['ticker', 'infrastructure', 'name'])\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"ğŸ“Š Duplicate Tickers by Infrastructure\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    for ticker in sorted(duplicate_tickers)[:10]:  # Show first 10\n",
        "        ticker_assets = duplicates_df[duplicates_df['ticker'] == ticker]\n",
        "        print(f\"\\n{ticker} ({len(ticker_assets)} assets):\")\n",
        "        for _, row in ticker_assets.iterrows():\n",
        "            infra = row['infrastructure'] if pd.notna(row['infrastructure']) else 'N/A'\n",
        "            print(f\"   - {row['name']} (slug: {row['slug']}, infrastructure: {infra})\")\n",
        "    \n",
        "    if len(duplicate_tickers) > 10:\n",
        "        print(f\"\\n... and {len(duplicate_tickers) - 10} more duplicate tickers\")\n",
        "    \n",
        "    return duplicates_df\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "print(\"âœ… Helper functions loaded!\")\n",
        "print(\"\\nAvailable functions:\")\n",
        "print(\"   - get_slugs_by_ticker('DOGE') - Get all DOGE assets\")\n",
        "print(\"   - get_slug_by_ticker_and_infrastructure('DOGE', 'ETH') - Get ETH-based DOGE slug\")\n",
        "print(\"   - filter_duplicates_by_infrastructure() - Show duplicates grouped by infrastructure\")\n",
        "print(\"\\nExample:\")\n",
        "print(\"   doge_slugs = get_slugs_by_ticker('DOGE')\")\n",
        "print(\"   eth_doge_slug = get_slug_by_ticker_and_infrastructure('DOGE', 'ETH')\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Proofofconcept",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
